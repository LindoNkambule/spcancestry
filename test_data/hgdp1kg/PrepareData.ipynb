{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc46e64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import hail as hl\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7adac9",
   "metadata": {},
   "source": [
    "### Sample annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38cfcf40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://gcp-public-data--gnomad/release/3.1/secondary_analyses/hgdp_1kg/data_intersection/hgdp_1kg_sample_info.unrelateds.pca_outliers_removed.with_project.tsv...\n",
      "- [1 files][ 56.2 KiB/ 56.2 KiB]                                                \n",
      "Operation completed over 1 objects/56.2 KiB.                                     \n"
     ]
    }
   ],
   "source": [
    "! gsutil cp gs://gcp-public-data--gnomad/release/3.1/secondary_analyses/hgdp_1kg/data_intersection/hgdp_1kg_sample_info.unrelateds.pca_outliers_removed.with_project.tsv .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d89b0681",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_annotations = pd.read_table('hgdp_1kg_sample_info.unrelateds.pca_outliers_removed.with_project.tsv',\n",
    "                                   header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90f35c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 3380\n",
      "Truth samples: 3042\n",
      "Unknown samples:  338\n"
     ]
    }
   ],
   "source": [
    "# get sample IDs and randomly (90/10) split data into truth and unknown\n",
    "random.seed(1234)\n",
    "samples = list(sample_annotations['Sample'].values)\n",
    "N = len(samples)\n",
    "truth_sample_ridx = random.sample(list(range(0, N)), int(N * 0.9))\n",
    "truth_samples = [samples[i] for i in truth_sample_ridx]\n",
    "unknown_samples = list(set(samples) - set(truth_samples))\n",
    "\n",
    "assert (len(truth_samples + unknown_samples)) == len(samples)\n",
    "assert len(list(set(truth_samples) & set(unknown_samples))) == 0\n",
    "\n",
    "print(f'Total samples: {N}\\nTruth samples: {len(truth_samples)}\\nUnknown samples:  {len(unknown_samples)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "505a69ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# truth\n",
    "truth_annotations = sample_annotations.loc[sample_annotations['Sample'].isin(truth_samples)]\n",
    "truth_annotations = truth_annotations[['Sample', 'SuperPop']]\n",
    "truth_annotations.to_csv('hgdp_1kg_truth_labels.txt', sep ='\\t', index=False)\n",
    "\n",
    "# unknown\n",
    "unknown_annotations = sample_annotations.loc[sample_annotations['Sample'].isin(unknown_samples)]\n",
    "unknown_annotations = unknown_annotations[['Sample', 'SuperPop']]\n",
    "unknown_annotations.to_csv('hgdp_1kg_unknown_labels.txt', sep ='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301b67d2",
   "metadata": {},
   "source": [
    "### Randomly split data into truth (gold standard) and unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a48dad73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing Hail with default parameters...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/20 20:23:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/20 20:23:07 WARN Hail: This Hail JAR was compiled for Spark 3.3.0, running with Spark 3.3.2.\n",
      "  Compatibility is not guaranteed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running on Apache Spark version 3.3.2\n",
      "SparkUI available at http://10.0.0.207:4040\n",
      "Welcome to\n",
      "     __  __     <>__\n",
      "    / /_/ /__  __/ /\n",
      "   / __  / _ `/ / /\n",
      "  /_/ /_/\\_,_/_/_/   version 0.2.112-31ceff2fb5fd\n",
      "LOGGING: writing to /Volumes/ExternalDrive/SPCAncestry/data/hgdp_1kg/hail-20230320-2023-0.2.112-31ceff2fb5fd.log\n"
     ]
    }
   ],
   "source": [
    "mt = hl.read_matrix_table('unrelateds_without_outliers.mt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db05e465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199974, 3378)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83cadcc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:==================================================>(49999 + 1) / 50000]\r"
     ]
    }
   ],
   "source": [
    "# data has very few variants but lots of partitions\n",
    "mt = mt.checkpoint('hgdp_1kg_checkpoint.mt')\n",
    "# mt_rep = mt.repartition(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8b77fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt = hl.read_matrix_table('hgdp_1kg_checkpoint.mt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc606a78",
   "metadata": {},
   "source": [
    "### Do a 90/10 split, and the 90% will be used to train and infer POP labels on the 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e1dce57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:==================================================>(49999 + 1) / 50000]\r"
     ]
    }
   ],
   "source": [
    "# truth\n",
    "truth_mt = mt.filter_cols(hl.literal(truth_samples).contains(mt['s']), keep=True)\n",
    "# the annotations file has more samples\n",
    "# assert truth_mt.count_cols() == len(truth_samples)\n",
    "\n",
    "# unknown\n",
    "unknown_mt = mt.filter_cols(hl.literal(unknown_samples).contains(mt['s']), keep=True)\n",
    "# assert unknown_mt.count_cols() == len(unknown_samples)\n",
    "\n",
    "hl.export_plink(truth_mt, 'hgdp_1kg_truth', ind_id = truth_mt.s)\n",
    "hl.export_plink(unknown_mt, 'hgdp_1kg_unknown', ind_id = unknown_mt.s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaa9c76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
