{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02c4fe01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import spcancestry\n",
    "from gnomad.sample_qc.ancestry import assign_population_pcs\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, RocCurveDisplay\n",
    "from sklearn.preprocessing import label_binarize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cf7b77",
   "metadata": {},
   "source": [
    "# 1. Comparing SPCAncestry stacking with gnomAD RF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e2cda5",
   "metadata": {},
   "source": [
    "## 1A. HGDP1KG data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28150547",
   "metadata": {},
   "source": [
    "### SPCAncestry stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dcde13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 00:31:03.916 Hail: INFO: Found 3021 samples in fam file.\n",
      "2023-05-09 00:31:03.916 Hail: INFO: Found 199974 variants in bim file.\n",
      "2023-05-09 00:31:04.833 Hail: INFO: Found 335 samples in fam file.\n",
      "2023-05-09 00:31:04.833 Hail: INFO: Found 199974 variants in bim file.\n"
     ]
    }
   ],
   "source": [
    "path = '/Volumes/ExternalDrive/SPCAncestry/data/hgdp_1kg/'\n",
    "inref_mt = spcancestry.Read(file=f'{path}hgdp_1kg_truth.bed', qc=False).as_matrixtable()\n",
    "input_mt = spcancestry.Read(file=f'{path}hgdp_1kg_unknown.fam', qc=False).as_matrixtable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18043764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intersecting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:====================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(199974, 3021)\n",
      "(199974, 335)\n",
      "Running reference PCA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 00:31:51.583 Hail: INFO: hwe_normalize: found 199974 variants after filtering out monomorphic sites.\n",
      "2023-05-09 00:32:07.037 Hail: INFO: pca: running PCA with 20 components... / 10]\n",
      "2023-05-09 00:49:34.701 Hail: INFO: Coerced sorted dataset         (8 + 2) / 10]\n",
      "2023-05-09 00:50:11.504 Hail: INFO: wrote table with 199974 rows in 10 partitions to /tmp/persist_TableDM34xXtziq\n",
      "2023-05-09 00:50:13.208 Hail: INFO: Reading table without type imputation\n",
      "  Loading field 'Sample' as type str (not specified)\n",
      "  Loading field 'SuperPop' as type str (not specified)\n",
      "2023-05-09 00:50:13.860 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2023-05-09 00:50:14.137 Hail: INFO: Coerced sorted dataset\n",
      "2023-05-09 00:50:16.616 Hail: WARN: cols(): Resulting column table is sorted by 'col_key'.\n",
      "    To preserve matrix table column order, first unkey columns with 'key_cols_by()'\n",
      "2023-05-09 00:50:53.853 Hail: INFO: Coerced sorted dataset          (1 + 1) / 2]\n"
     ]
    }
   ],
   "source": [
    "# The following will:\n",
    "# 1. Intersect the two datasets to make sure we are using the same set of SNPs for training+inference\n",
    "# 2. Compute PCs using reference data (from the 1)\n",
    "# 3. Project unknown samples onto reference PC space (from 2)\n",
    "scores_df, colnames = spcancestry.PCProject(ref_mt=inref_mt, data_mt=input_mt,\n",
    "                                            ref_info=f'{path}hgdp_1kg_truth_labels.txt').run_pca_projection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed48debf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s</th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "      <th>PC7</th>\n",
       "      <th>PC8</th>\n",
       "      <th>PC9</th>\n",
       "      <th>...</th>\n",
       "      <th>PC12</th>\n",
       "      <th>PC13</th>\n",
       "      <th>PC14</th>\n",
       "      <th>PC15</th>\n",
       "      <th>PC16</th>\n",
       "      <th>PC17</th>\n",
       "      <th>PC18</th>\n",
       "      <th>PC19</th>\n",
       "      <th>PC20</th>\n",
       "      <th>SuperPop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HG00096</td>\n",
       "      <td>-0.130653</td>\n",
       "      <td>0.250466</td>\n",
       "      <td>-0.027431</td>\n",
       "      <td>-0.082609</td>\n",
       "      <td>-0.014573</td>\n",
       "      <td>0.001607</td>\n",
       "      <td>0.06208</td>\n",
       "      <td>0.018693</td>\n",
       "      <td>-0.000118</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.00559</td>\n",
       "      <td>-0.000164</td>\n",
       "      <td>-0.009424</td>\n",
       "      <td>0.005099</td>\n",
       "      <td>-0.002693</td>\n",
       "      <td>0.016227</td>\n",
       "      <td>-0.01332</td>\n",
       "      <td>0.003618</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>EUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HG00097</td>\n",
       "      <td>-0.129984</td>\n",
       "      <td>0.247212</td>\n",
       "      <td>-0.024903</td>\n",
       "      <td>-0.084724</td>\n",
       "      <td>-0.011458</td>\n",
       "      <td>0.002756</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.017586</td>\n",
       "      <td>-0.003013</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006396</td>\n",
       "      <td>-0.003164</td>\n",
       "      <td>-0.009694</td>\n",
       "      <td>0.00103</td>\n",
       "      <td>-0.001513</td>\n",
       "      <td>0.007614</td>\n",
       "      <td>-0.002749</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.00541</td>\n",
       "      <td>EUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HG00099</td>\n",
       "      <td>-0.130497</td>\n",
       "      <td>0.246637</td>\n",
       "      <td>-0.026746</td>\n",
       "      <td>-0.083507</td>\n",
       "      <td>-0.008789</td>\n",
       "      <td>0.002276</td>\n",
       "      <td>0.064794</td>\n",
       "      <td>0.015948</td>\n",
       "      <td>-0.00385</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004857</td>\n",
       "      <td>0.001914</td>\n",
       "      <td>-0.008211</td>\n",
       "      <td>0.001449</td>\n",
       "      <td>-0.002011</td>\n",
       "      <td>0.01137</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.003164</td>\n",
       "      <td>0.001668</td>\n",
       "      <td>EUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HG00100</td>\n",
       "      <td>-0.12885</td>\n",
       "      <td>0.250958</td>\n",
       "      <td>-0.024698</td>\n",
       "      <td>-0.088106</td>\n",
       "      <td>-0.011255</td>\n",
       "      <td>0.00257</td>\n",
       "      <td>0.050964</td>\n",
       "      <td>0.018685</td>\n",
       "      <td>-0.003741</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016691</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>-0.006142</td>\n",
       "      <td>0.003748</td>\n",
       "      <td>0.001364</td>\n",
       "      <td>0.010581</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>0.002789</td>\n",
       "      <td>-0.000287</td>\n",
       "      <td>EUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HG00103</td>\n",
       "      <td>-0.129443</td>\n",
       "      <td>0.246409</td>\n",
       "      <td>-0.025154</td>\n",
       "      <td>-0.089888</td>\n",
       "      <td>-0.009347</td>\n",
       "      <td>0.005414</td>\n",
       "      <td>0.059072</td>\n",
       "      <td>0.017929</td>\n",
       "      <td>-0.001648</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014377</td>\n",
       "      <td>-0.002957</td>\n",
       "      <td>-0.007067</td>\n",
       "      <td>0.000623</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.008775</td>\n",
       "      <td>-0.001966</td>\n",
       "      <td>-0.003394</td>\n",
       "      <td>-0.000298</td>\n",
       "      <td>EUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>NA20903</td>\n",
       "      <td>-0.123742</td>\n",
       "      <td>0.083491</td>\n",
       "      <td>0.125892</td>\n",
       "      <td>0.132143</td>\n",
       "      <td>0.025654</td>\n",
       "      <td>-0.000135</td>\n",
       "      <td>0.008899</td>\n",
       "      <td>0.004622</td>\n",
       "      <td>-0.00147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003159</td>\n",
       "      <td>-0.00067</td>\n",
       "      <td>-0.00364</td>\n",
       "      <td>-0.001181</td>\n",
       "      <td>0.002269</td>\n",
       "      <td>0.006341</td>\n",
       "      <td>0.001097</td>\n",
       "      <td>-0.002091</td>\n",
       "      <td>0.001862</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>NA21108</td>\n",
       "      <td>-0.124049</td>\n",
       "      <td>0.109607</td>\n",
       "      <td>0.099954</td>\n",
       "      <td>0.106831</td>\n",
       "      <td>0.019539</td>\n",
       "      <td>-0.001934</td>\n",
       "      <td>0.008966</td>\n",
       "      <td>-0.004078</td>\n",
       "      <td>-0.001156</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001278</td>\n",
       "      <td>-0.002778</td>\n",
       "      <td>0.002377</td>\n",
       "      <td>0.000648</td>\n",
       "      <td>-0.003439</td>\n",
       "      <td>0.006679</td>\n",
       "      <td>-0.002601</td>\n",
       "      <td>0.002786</td>\n",
       "      <td>0.008124</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>NA21114</td>\n",
       "      <td>-0.125164</td>\n",
       "      <td>0.066609</td>\n",
       "      <td>0.13435</td>\n",
       "      <td>0.151027</td>\n",
       "      <td>0.029075</td>\n",
       "      <td>-0.001849</td>\n",
       "      <td>0.011448</td>\n",
       "      <td>0.007847</td>\n",
       "      <td>0.002058</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003778</td>\n",
       "      <td>-0.000728</td>\n",
       "      <td>-0.00489</td>\n",
       "      <td>-0.004165</td>\n",
       "      <td>0.001264</td>\n",
       "      <td>-0.002094</td>\n",
       "      <td>0.001562</td>\n",
       "      <td>-0.000529</td>\n",
       "      <td>-0.009356</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>NA21129</td>\n",
       "      <td>-0.129031</td>\n",
       "      <td>0.063162</td>\n",
       "      <td>0.141917</td>\n",
       "      <td>0.15565</td>\n",
       "      <td>0.029053</td>\n",
       "      <td>-0.001486</td>\n",
       "      <td>0.011335</td>\n",
       "      <td>0.002948</td>\n",
       "      <td>0.001191</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002679</td>\n",
       "      <td>-0.001316</td>\n",
       "      <td>-0.004069</td>\n",
       "      <td>0.001601</td>\n",
       "      <td>-0.002589</td>\n",
       "      <td>-0.001069</td>\n",
       "      <td>0.000738</td>\n",
       "      <td>0.002867</td>\n",
       "      <td>-0.012532</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>NA21142</td>\n",
       "      <td>-0.123115</td>\n",
       "      <td>0.066187</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.154541</td>\n",
       "      <td>0.026297</td>\n",
       "      <td>-0.000247</td>\n",
       "      <td>0.010034</td>\n",
       "      <td>0.010038</td>\n",
       "      <td>0.003393</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002749</td>\n",
       "      <td>-0.001675</td>\n",
       "      <td>-0.008171</td>\n",
       "      <td>-0.002486</td>\n",
       "      <td>0.001357</td>\n",
       "      <td>-0.005672</td>\n",
       "      <td>0.004443</td>\n",
       "      <td>-0.001634</td>\n",
       "      <td>-0.007669</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3356 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           s       PC1       PC2       PC3       PC4       PC5       PC6   \n",
       "0    HG00096 -0.130653  0.250466 -0.027431 -0.082609 -0.014573  0.001607  \\\n",
       "1    HG00097 -0.129984  0.247212 -0.024903 -0.084724 -0.011458  0.002756   \n",
       "2    HG00099 -0.130497  0.246637 -0.026746 -0.083507 -0.008789  0.002276   \n",
       "3    HG00100  -0.12885  0.250958 -0.024698 -0.088106 -0.011255   0.00257   \n",
       "4    HG00103 -0.129443  0.246409 -0.025154 -0.089888 -0.009347  0.005414   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "330  NA20903 -0.123742  0.083491  0.125892  0.132143  0.025654 -0.000135   \n",
       "331  NA21108 -0.124049  0.109607  0.099954  0.106831  0.019539 -0.001934   \n",
       "332  NA21114 -0.125164  0.066609   0.13435  0.151027  0.029075 -0.001849   \n",
       "333  NA21129 -0.129031  0.063162  0.141917   0.15565  0.029053 -0.001486   \n",
       "334  NA21142 -0.123115  0.066187  0.137931  0.154541  0.026297 -0.000247   \n",
       "\n",
       "          PC7       PC8       PC9  ...      PC12      PC13      PC14   \n",
       "0     0.06208  0.018693 -0.000118  ...  -0.00559 -0.000164 -0.009424  \\\n",
       "1    0.060606  0.017586 -0.003013  ... -0.006396 -0.003164 -0.009694   \n",
       "2    0.064794  0.015948  -0.00385  ... -0.004857  0.001914 -0.008211   \n",
       "3    0.050964  0.018685 -0.003741  ... -0.016691  0.000592 -0.006142   \n",
       "4    0.059072  0.017929 -0.001648  ... -0.014377 -0.002957 -0.007067   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "330  0.008899  0.004622  -0.00147  ...  0.003159  -0.00067  -0.00364   \n",
       "331  0.008966 -0.004078 -0.001156  ... -0.001278 -0.002778  0.002377   \n",
       "332  0.011448  0.007847  0.002058  ...  0.003778 -0.000728  -0.00489   \n",
       "333  0.011335  0.002948  0.001191  ...  0.002679 -0.001316 -0.004069   \n",
       "334  0.010034  0.010038  0.003393  ... -0.002749 -0.001675 -0.008171   \n",
       "\n",
       "         PC15      PC16      PC17      PC18      PC19      PC20  SuperPop  \n",
       "0    0.005099 -0.002693  0.016227  -0.01332  0.003618  0.000119       EUR  \n",
       "1     0.00103 -0.001513  0.007614 -0.002749  0.004455  -0.00541       EUR  \n",
       "2    0.001449 -0.002011   0.01137  0.000295  0.003164  0.001668       EUR  \n",
       "3    0.003748  0.001364  0.010581 -0.000015  0.002789 -0.000287       EUR  \n",
       "4    0.000623   0.00004  0.008775 -0.001966 -0.003394 -0.000298       EUR  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "330 -0.001181  0.002269  0.006341  0.001097 -0.002091  0.001862      <NA>  \n",
       "331  0.000648 -0.003439  0.006679 -0.002601  0.002786  0.008124      <NA>  \n",
       "332 -0.004165  0.001264 -0.002094  0.001562 -0.000529 -0.009356      <NA>  \n",
       "333  0.001601 -0.002589 -0.001069  0.000738  0.002867 -0.012532      <NA>  \n",
       "334 -0.002486  0.001357 -0.005672  0.004443 -0.001634 -0.007669      <NA>  \n",
       "\n",
       "[3356 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The output will contain PCs for both the training and unknown samples\n",
    "# Unknown samples will have NA in the SuperPop column\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85b9d0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated error rate for the meta model is 0.0016528925619834212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/spcancestry/spcancestry.py:208: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  unknown_data.loc[:, output_col] = clf.predict(unknown_data[pc_cols].values)\n"
     ]
    }
   ],
   "source": [
    "# infer ancestry using spcancestry and gnomAD RF\n",
    "spcancestry_infered = spcancestry.infer_ancestry(scores_df, colnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3deb1c",
   "metadata": {},
   "source": [
    "### gnomAD RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4592672",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import random\n",
    "from typing import Any, Counter, List, Optional, Tuple, Union\n",
    "\n",
    "import hail as hl\n",
    "import pandas as pd\n",
    "\n",
    "logging.basicConfig(format=\"%(levelname)s (%(name)s %(lineno)s): %(message)s\")\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "def assign_population_pcs_bug_fixed(\n",
    "    pop_pca_scores: Union[hl.Table, pd.DataFrame],\n",
    "    pc_cols: Union[hl.expr.ArrayExpression, List[int], List[str]],\n",
    "    known_col: str = \"known_pop\",\n",
    "    fit: Any = None,  # Type should be RandomForestClassifier but we do not want to import sklearn.RandomForestClassifier outside\n",
    "    seed: int = 42,\n",
    "    prop_train: float = 0.8,\n",
    "    n_estimators: int = 100,\n",
    "    min_prob: float = 0.9,\n",
    "    output_col: str = \"pop\",\n",
    "    missing_label: str = \"oth\",\n",
    "    pc_expr: Union[hl.expr.ArrayExpression, str] = \"scores\",\n",
    ") -> Tuple[\n",
    "    Union[hl.Table, pd.DataFrame], Any\n",
    "]:  # 2nd element of the tuple should be RandomForestClassifier but we do not want to import sklearn.RandomForestClassifier outside\n",
    "    \"\"\"\n",
    "    Use a random forest model to assign population labels based on the results of PCA.\n",
    "    Default values for model and assignment parameters are those used in gnomAD.\n",
    "    As input, this function can either take:\n",
    "        - A Hail Table (typically the output of `hwe_normalized_pca`). In this case,\n",
    "            - `pc_cols` should be one of::\n",
    "                - A list of integers where each element is one of the PCs to use.\n",
    "                - A list of strings where each element is one of the PCs to use.\n",
    "                - An ArrayExpression of Floats where each element is one of the PCs.\n",
    "                  to use\n",
    "            - A Hail Table will be returned as output.\n",
    "        - A Pandas DataFrame. In this case:\n",
    "            - Each PC should be in a separate column and `pc_cols` is the list of all\n",
    "              the columns containing the PCs to use.\n",
    "            - A pandas DataFrame is returned as output.\n",
    "    .. note::\n",
    "        If you have a Pandas Dataframe and have all PCs as an array in a single column,\n",
    "        the `expand_pd_array_col`can be used to expand this column into multiple `PC`\n",
    "        columns.\n",
    "    :param pop_pca_scores: Input Hail Table or Pandas Dataframe.\n",
    "    :param pc_cols: List of which PCs to use/columns storing the PCs to use. Values\n",
    "        provided should be 1-based and should be a list of integers when passing in a\n",
    "        Hail Table (i.e. [1, 2, 4, 5]) or a list of strings when passing in a Pandas\n",
    "        Dataframe (i.e. [\"PC1\", \"PC2\", \"PC4\", \"PC5\"]). When passing a HT this can also\n",
    "        be an ArrayExpression containing all the PCs to use.\n",
    "    :param known_col: Column storing the known population labels.\n",
    "    :param fit: Fit from a previously trained random forest model (i.e., the output\n",
    "        from a previous RandomForestClassifier() call).\n",
    "    :param seed: Random seed.\n",
    "    :param prop_train: Proportion of known data used for training.\n",
    "    :param n_estimators: Number of trees to use in the RF model.\n",
    "    :param min_prob: Minimum probability of belonging to a given population for the\n",
    "        population to be set (otherwise set to `None`).\n",
    "    :param output_col: Output column storing the assigned population.\n",
    "    :param missing_label: Label for samples for which the assignment probability is\n",
    "        smaller than `min_prob`.\n",
    "    :param pc_expr: Column storing the list of PCs. Only used if `pc_cols` is a List of\n",
    "        integers. Default is scores.\n",
    "    :return: Hail Table or Pandas Dataframe (depending on input) containing sample IDs\n",
    "        and imputed population labels, trained random forest model.\n",
    "    \"\"\"\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "    hail_input = isinstance(pop_pca_scores, hl.Table)\n",
    "    if hail_input:\n",
    "        if isinstance(pc_cols, list):\n",
    "            if not all(isinstance(n, int) for n in pc_cols):\n",
    "                raise TypeError(\n",
    "                    \"Using a Hail Table with a list of PC cols to use (pc_cols) \"\n",
    "                    \"requires all values of the pc_cols list to be integers.\"\n",
    "                )\n",
    "            if isinstance(pc_expr, str):\n",
    "                pc_expr = pop_pca_scores[pc_expr]\n",
    "            pcs_to_pull = [pc_expr[i - 1] for i in pc_cols]\n",
    "        else:\n",
    "            pc_col_len = list(\n",
    "                filter(\n",
    "                    None,\n",
    "                    pop_pca_scores.aggregate(hl.agg.collect_as_set(hl.len(pc_cols))),\n",
    "                )\n",
    "            )\n",
    "            if len(pc_col_len) > 1:\n",
    "                raise ValueError(\n",
    "                    \"More than one length was found among the 'pc_cols' \"\n",
    "                    \"ArrayExpression values. The length must be consistent!\"\n",
    "                )\n",
    "            pcs_to_pull = pc_cols\n",
    "            pc_cols = list(range(1, pc_col_len[0] + 1))\n",
    "        if not fit:\n",
    "            pop_pca_scores = pop_pca_scores.select(known_col, pca_scores=pcs_to_pull)\n",
    "        else:\n",
    "            pop_pca_scores = pop_pca_scores.select(pca_scores=pcs_to_pull)\n",
    "\n",
    "        pop_pc_pd = pop_pca_scores.to_pandas()\n",
    "\n",
    "        # Explode the PC array\n",
    "        pc_cols = [f\"PC{i}\" for i in pc_cols]\n",
    "        pop_pc_pd[pc_cols] = pd.DataFrame(pop_pc_pd[\"pca_scores\"].values.tolist())\n",
    "\n",
    "    else:\n",
    "        if not all(isinstance(n, str) for n in pc_cols):\n",
    "            raise TypeError(\n",
    "                \"Using a Pandas DataFrame with pc_cols requires all values of the\"\n",
    "                \" pc_cols list to be strings.\"\n",
    "            )\n",
    "        pop_pc_pd = pop_pca_scores\n",
    "\n",
    "    # Split training data into subsamples for fitting and evaluating\n",
    "    if not fit:\n",
    "        train_data = pop_pc_pd.loc[~pop_pc_pd[known_col].isnull()]\n",
    "        N = len(train_data)\n",
    "        random.seed(seed)\n",
    "        train_subsample_ridx = random.sample(list(range(0, N)), int(N * prop_train))\n",
    "        train_fit = train_data.iloc[train_subsample_ridx]\n",
    "        fit_samples = [x for x in train_fit[\"s\"]]\n",
    "        evaluate_fit = train_data.loc[~train_data[\"s\"].isin(fit_samples)]\n",
    "\n",
    "        # Train RF\n",
    "        training_set_known_labels = train_fit[known_col].values\n",
    "        training_set_pcs = train_fit[pc_cols].values\n",
    "        evaluation_set_pcs = evaluate_fit[pc_cols].values\n",
    "\n",
    "        pop_clf = RandomForestClassifier(n_estimators=n_estimators, random_state=seed)\n",
    "        pop_clf.fit(training_set_pcs, training_set_known_labels)\n",
    "        print(\n",
    "            \"Random forest feature importances are as follows: {}\".format(\n",
    "                pop_clf.feature_importances_\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Evaluate RF\n",
    "        predictions = pop_clf.predict(evaluation_set_pcs)\n",
    "        error_rate = 1 - sum(evaluate_fit[known_col] == predictions) / float(\n",
    "            len(predictions)\n",
    "        )\n",
    "        print(\"Estimated error rate for RF model is {}\".format(error_rate))\n",
    "    else:\n",
    "        pop_clf = fit\n",
    "\n",
    "    # Classify data\n",
    "    pop_pc_pd[output_col] = pop_clf.predict(pop_pc_pd[pc_cols].values)\n",
    "    probs = pop_clf.predict_proba(pop_pc_pd[pc_cols].values)\n",
    "    probs = pd.DataFrame(probs, columns=[f\"prob_{p}\" for p in pop_clf.classes_])\n",
    "    pop_pc_pd = pd.concat([pop_pc_pd.reset_index(drop=True), probs.reset_index(drop=True)], axis=1)\n",
    "    # pop_pc_pd = pd.concat([pop_pc_pd, probs], axis=1)\n",
    "    probs[\"max\"] = probs.max(axis=1)\n",
    "    pop_pc_pd.loc[probs[\"max\"] < min_prob, output_col] = missing_label\n",
    "    pop_pc_pd = pop_pc_pd.drop(pc_cols, axis=\"columns\")\n",
    "\n",
    "    logger.info(\n",
    "        \"Found the following sample count after population assignment: %s\",\n",
    "        \", \".join(\n",
    "            f\"{pop}: {count}\" for pop, count in Counter(pop_pc_pd[output_col]).items()\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    if hail_input:\n",
    "        pops_ht = hl.Table.from_pandas(pop_pc_pd, key=list(pop_pca_scores.key))\n",
    "        pops_ht = pops_ht.annotate_globals(\n",
    "            assign_pops_from_pc_params=hl.struct(min_assignment_prob=min_prob)\n",
    "        )\n",
    "\n",
    "        if not fit:\n",
    "            pops_ht = pops_ht.annotate_globals(\n",
    "                assign_pops_from_pc_params=pops_ht.assign_pops_from_pc_params.annotate(\n",
    "                    error_rate=error_rate\n",
    "                )\n",
    "            )\n",
    "\n",
    "            pops_ht = pops_ht.annotate(\n",
    "                evaluation_sample=hl.literal(list(evaluate_fit.s)).contains(pops_ht.s),\n",
    "                training_sample=hl.literal(list(train_fit.s)).contains(pops_ht.s),\n",
    "            )\n",
    "        return pops_ht, pop_clf\n",
    "    else:\n",
    "        return pop_pc_pd, pop_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bfa2d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO (__main__ 156): Found the following sample count after population assignment: EUR: 651, oth: 50, EAS: 715, AMR: 381, CSA: 662, AFR: 744, OCE: 27, MID: 126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest feature importances are as follows: [0.19354746 0.17704245 0.16032011 0.12148441 0.1125968  0.05376226\n",
      " 0.04073679 0.0272037  0.02257492 0.01713482 0.01024832 0.01889163\n",
      " 0.00742205 0.01143318 0.00380711 0.00130609 0.00644453 0.00429563\n",
      " 0.00423795 0.00550978]\n",
      "Estimated error rate for RF model is 0.0016528925619834212\n"
     ]
    }
   ],
   "source": [
    "# gnomAD overwrites the df, so make a copy first\n",
    "scores_df_gnomad = scores_df.copy()\n",
    "gnomad_infered, gnomad_mod = assign_population_pcs_bug_fixed(scores_df_gnomad, colnames, known_col='SuperPop')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac2283f",
   "metadata": {},
   "source": [
    "### Export files for plotting in ggplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16b7c99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out files for plotting in R\n",
    "# gnomAD DF still contains training samples, remove them\n",
    "gnomad_infered_filt = gnomad_infered[gnomad_infered['s'].isin(list(spcancestry_infered['s'].values))]\n",
    "gnomad_infered_filt = gnomad_infered_filt.drop(columns=['SuperPop'])\n",
    "\n",
    "# truth labels for annotating\n",
    "truth_labels = pd.read_table(f'{path}hgdp_1kg_unknown_labels.txt',\n",
    "                            header=0, names=['s', 'true_pop'])\n",
    "\n",
    "# add TRUE population labels\n",
    "spcancestry_infered_annotated = pd.merge(spcancestry_infered, truth_labels, on='s', how='left')\n",
    "gnomad_infered_annotated = pd.merge(gnomad_infered_filt, truth_labels, on='s', how='left')\n",
    "\n",
    "# write out data to files\n",
    "spcancestry_infered_annotated.to_csv('spcancestry_probs.txt', sep='\\t', index=False)\n",
    "gnomad_infered_annotated.to_csv('gnomad_probs.txt', sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d802526",
   "metadata": {},
   "source": [
    "# 2. Impact of the number of PCs on classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c845d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated error rate for the meta model is 0.0380165289256198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/spcancestry/spcancestry.py:208: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  unknown_data.loc[:, output_col] = clf.predict(unknown_data[pc_cols].values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated error rate for the meta model is 0.0016528925619834212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/spcancestry/spcancestry.py:208: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  unknown_data.loc[:, output_col] = clf.predict(unknown_data[pc_cols].values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated error rate for the meta model is 0.0016528925619834212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/spcancestry/spcancestry.py:208: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  unknown_data.loc[:, output_col] = clf.predict(unknown_data[pc_cols].values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated error rate for the meta model is 0.0016528925619834212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/spcancestry/spcancestry.py:208: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  unknown_data.loc[:, output_col] = clf.predict(unknown_data[pc_cols].values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated error rate for the meta model is 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/spcancestry/spcancestry.py:208: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  unknown_data.loc[:, output_col] = clf.predict(unknown_data[pc_cols].values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated error rate for the meta model is 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/spcancestry/spcancestry.py:208: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  unknown_data.loc[:, output_col] = clf.predict(unknown_data[pc_cols].values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated error rate for the meta model is 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/spcancestry/spcancestry.py:208: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  unknown_data.loc[:, output_col] = clf.predict(unknown_data[pc_cols].values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated error rate for the meta model is 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/spcancestry/spcancestry.py:208: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  unknown_data.loc[:, output_col] = clf.predict(unknown_data[pc_cols].values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated error rate for the meta model is 0.0016528925619834212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/spcancestry/spcancestry.py:208: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  unknown_data.loc[:, output_col] = clf.predict(unknown_data[pc_cols].values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated error rate for the meta model is 0.0016528925619834212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/spcancestry/spcancestry.py:208: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  unknown_data.loc[:, output_col] = clf.predict(unknown_data[pc_cols].values)\n"
     ]
    }
   ],
   "source": [
    "# see how varying the number of PCs used as features impacts classification accuracy\n",
    "\n",
    "# truth labels for annotating\n",
    "truth_labels = pd.read_table(f'{path}hgdp_1kg_unknown_labels.txt',\n",
    "                            header=0, names=['s', 'true_pop'])\n",
    "\n",
    "def vary_pcs(scores_features_df: pd.DataFrame = None,\n",
    "            num_pcs: int = None):\n",
    "    \"\"\"\n",
    "        For investigating how classification accuracy changes with number of PCs used as features\n",
    "    \"\"\"\n",
    "    # subset scores df to only just the number of specified PCs\n",
    "    pcs_colnames = [f'PC{i+1}' for i in range(num_pcs)]\n",
    "    cols_subset = ['s', 'SuperPop'] + pcs_colnames\n",
    "    scores_subset = scores_features_df[cols_subset]\n",
    "    \n",
    "    # infer ancestry using spcancestry\n",
    "    infered = spcancestry.infer_ancestry(scores_subset, pcs_colnames)\n",
    "    infered_subset = infered[['s', 'pop']]\n",
    "    infered_subset = infered_subset.rename(columns={'pop': f'pcs_{num_pcs}'})\n",
    "    \n",
    "    return infered_subset\n",
    "\n",
    "\n",
    "merged_df = pd.DataFrame()\n",
    "\n",
    "for n_pcs in [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]:\n",
    "    pcs_df = vary_pcs(scores_df, n_pcs)\n",
    "    \n",
    "    if merged_df.empty:\n",
    "        merged_df = pcs_df\n",
    "    else:\n",
    "        merged_df = merged_df.merge(pcs_df, on='s', how='left')\n",
    "        \n",
    "# Add true population labels\n",
    "merged_df_annotated = merged_df.merge(truth_labels, on='s', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a42ae23b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classification</th>\n",
       "      <th>pcs_2</th>\n",
       "      <th>pcs_4</th>\n",
       "      <th>pcs_6</th>\n",
       "      <th>pcs_8</th>\n",
       "      <th>pcs_10</th>\n",
       "      <th>pcs_12</th>\n",
       "      <th>pcs_14</th>\n",
       "      <th>pcs_16</th>\n",
       "      <th>pcs_18</th>\n",
       "      <th>pcs_20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Match</td>\n",
       "      <td>299</td>\n",
       "      <td>334</td>\n",
       "      <td>333</td>\n",
       "      <td>333</td>\n",
       "      <td>333</td>\n",
       "      <td>333</td>\n",
       "      <td>333</td>\n",
       "      <td>333</td>\n",
       "      <td>333</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mismatch</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Unclassified</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  classification  pcs_2  pcs_4  pcs_6  pcs_8  pcs_10  pcs_12  pcs_14  pcs_16   \n",
       "0          Match    299    334    333    333     333     333     333     333  \\\n",
       "1       Mismatch      6      0      0      0       0       0       0       0   \n",
       "2   Unclassified     30      1      2      2       2       2       2       2   \n",
       "\n",
       "   pcs_18  pcs_20  \n",
       "0     333     333  \n",
       "1       0       0  \n",
       "2       2       2  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcs_cols = [f'pcs_{i}' for i in range(2, 22, 2)]\n",
    "\n",
    "classification_counts = {'classification': ['Match', 'Mismatch', 'Unclassified']}\n",
    "\n",
    "for npcs in pcs_cols:\n",
    "    pcs_df = merged_df_annotated[[npcs, 'true_pop']]\n",
    "    matches = (pcs_df[npcs] == pcs_df['true_pop']).sum()\n",
    "    mismatches = ((pcs_df[npcs] != pcs_df['true_pop']) & ((pcs_df[npcs] != 'oth'))).sum()\n",
    "    unclassified = (pcs_df[npcs] == 'oth').sum()\n",
    "    assert (matches+mismatches+unclassified) == merged_df_annotated.shape[0]\n",
    "    \n",
    "    classification_counts[npcs] = [matches, mismatches, unclassified]\n",
    "    \n",
    "df_counts = pd.DataFrame(classification_counts)\n",
    "df_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f0c599",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
